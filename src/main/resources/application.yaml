# =============================================================================
# LLM Gateway - 基礎共用配置
# =============================================================================
# 此檔案包進 Docker Image，包含所有環境共用的配置
# 環境特定配置透過 config/ 目錄下的 profile 檔案覆蓋
#
# 環境變數命名規則:
#   - 應用程式專屬: 使用 Spring 屬性名稱 (如 spring.profiles.default)
#   - 業界標準: 保持原樣 (如 OTEL_EXPORTER_OTLP_ENDPOINT)
# =============================================================================

spring:
  application:
    name: gate
  # 啟用 Virtual Threads (Java 21+)
  # 對 I/O 密集型 API Gateway 有顯著效能提升
  threads:
    virtual:
      enabled: true
  # 啟用 @Observed 註解支援（預先配置，確保專案一致性）
  observations:
    annotations:
      enabled: true
  security:
    oauth2:
      resourceserver:
        jwt:
          # 預設值供 AOT 編譯使用，執行時由各環境提供 gate-jwt-jwk-set-uri 屬性覆蓋
          jwk-set-uri: ${gate-jwt-jwk-set-uri:https://placeholder.example.com/.well-known/jwks.json}
  profiles:
    # 預設 profiles（可被 spring.profiles.active 覆蓋）
    # 本地開發: 自動使用 local,dev
    default: local,dev
  cloud:
    # 禁用 RefreshScope - Spring Cloud RefreshScope 不支援 AOT/Native Image
    # 參考: https://github.com/spring-cloud/spring-cloud-release/wiki/AOT-transformations-and-native-image-support
    refresh:
      enabled: false
    gateway:
      server:
        webmvc:
          enabled: true
    # Spring Cloud Stream 配置
    # Binary Mode: CloudEvents 屬性在 message attributes，data 在 body
    stream:
      bindings:
        # API 用量事件（Gate 代理 Anthropic API 的用量）
        usageEvent-out-0:
          destination: llm-gateway-usage
          content-type: application/json

# =============================================================================
# 伺服器配置
# =============================================================================
# server:
#   # HTTP 回應壓縮
#   # 注意：不壓縮 text/event-stream！
#   # SSE 串流需要即時送達，壓縮會造成緩衝延遲
#   # 參考: https://github.com/eclipse-ee4j/jersey/issues/3809
#   compression:
#     enabled: true
#     # 只壓縮非串流回應（不包含 text/event-stream）
#     mime-types: application/json,text/plain,text/html
#     min-response-size: 1024

  # Tomcat 配置（配合 Cloud Run containerConcurrency）
  # 計算公式參考：
  #   max-connections = containerConcurrency × 2
  #   accept-count = containerConcurrency × 0.5
  # 參考: https://docs.cloud.google.com/run/docs/about-concurrency
  tomcat:
    # 最大連線數 = containerConcurrency(80) × 2 = 160
    # 留 buffer 處理 Keep-Alive 連線和過渡期
    max-connections: 160
    # 等待佇列 = containerConcurrency(80) × 0.5 = 40
    # Cloud Run 會自動擴展，不需要大量佇列
    accept-count: 40
    # 連線超時（毫秒）：客戶端建立 TCP 連線的超時
    connection-timeout: 30000
    # Keep-Alive 超時（毫秒）：閒置連線保持時間
    keep-alive-timeout: 60000
    # 注意：Virtual Threads 啟用後，maxThreads 由 VirtualThreadPerTaskExecutor 管理
    # 不需要手動設定 server.tomcat.threads.max

# =============================================================================
# RestClient / HTTP Client 配置
# =============================================================================
spring.http.client:
  # 連線超時：建立 TCP 連線的最大等待時間
  connect-timeout: 10s
  # 讀取超時：等待回應資料的最大時間
  # LLM 串流回應可能很長，設定較長的超時
  read-timeout: 600s

# Anthropic API 配置
anthropic:
  api:
    base-url: https://api.anthropic.com
    keys: []

# Resilience4j 配置
# 注意：LLM API 呼叫時間較長，需調整超時閾值
resilience4j:
  circuitbreaker:
    instances:
      anthropic-api:
        # 失敗率達 50% 時觸發熔斷
        failure-rate-threshold: 50
        # 慢呼叫率達 80% 時觸發熔斷
        slow-call-rate-threshold: 80
        # LLM 串流回應可能需要數分鐘，設定 5 分鐘為慢呼叫閾值
        slow-call-duration-threshold: 300s
        # 熔斷器開啟後等待 60 秒再嘗試
        wait-duration-in-open-state: 60s
        # 半開狀態允許 10 個請求通過測試
        permitted-number-of-calls-in-half-open-state: 10
        # 滑動視窗大小
        sliding-window-size: 100
        sliding-window-type: COUNT_BASED

# Actuator 配置
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  health:
    livenessstate:
      enabled: true
    readinessstate:
      enabled: true
  # OpenTelemetry 配置 (Spring Boot 4.0)
  # 取樣率由環境 profile 控制 (lab=1.0, prod=0.1)
  # 本地開發: Docker Compose 自動偵測 grafana-lgtm 容器並配置 OTLP 端點
  # 部署環境: 設定業界標準環境變數 OTEL_EXPORTER_OTLP_ENDPOINT
  tracing:
    sampling:
      probability: 1.0

logging:
  level:
    root: INFO
